prometheus:
  prometheusSpec:
    externalLabels:
      cluster: k8s-eks       
    replicas: 1
    retention: 15d
    retentionSize: 80GiB
    walCompression: true
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    serviceMonitorNamespaceSelector: {}
    podMonitorNamespaceSelector: {}
    nodeSelector:
      role: obs
    tolerations:
      - key: role
        operator: Equal
        value: obs
        effect: NoSchedule
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi

prometheusOperator:
  nodeSelector: { role: obs }
  tolerations:
    - key: role
      operator: Equal
      value: obs
      effect: NoSchedule

alertmanager:
  alertmanagerSpec:
    nodeSelector: { role: obs }
    tolerations:
      - key: role
        operator: Equal
        value: obs
        effect: NoSchedule
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 20Gi

nodeExporter:
  tolerations:
    - operator: Exists

kubeStateMetrics:
  enabled: true
  nodeSelector: { role: obs }
  tolerations:
    - key: role
      operator: Equal
      value: obs
      effect: NoSchedule
      
grafana:
  enabled: true
  grafana.ini:
    server:
      root_url: "http://%(domain)s/grafana/"
      serve_from_sub_path: true
    feature_toggles:
      enable: correlations      # 버전별 안전빵
       
  # EFS(RWX) 퍼시스턴스
  persistence:
    enabled: true
    storageClassName: efs-rwx-grafana     # EFS SC
    accessModes: # RWX mode
      - ReadWriteMany
    size: 10Gi

  # EFS 권한/소유권 문제 예방 (init-chown-data 정상 동작)
  podSecurityContext:
    fsGroup: 472
    runAsUser: 472
    runAsGroup: 472
  securityContext:
    runAsUser: 472

  # 모니터링 전용 노드로 스케줄
  nodeSelector:
    role: obs
  tolerations:
    - key: role
      operator: Equal
      value: obs
      effect: NoSchedule

  # 서비스 노출 (원하는 방식 하나 선택)
  service:
    type: ClusterIP
    ports:
    - protocol: TCP
      port: 80
      targetPort: 3000

    #type: LoadBalancer
    #annotations: #최신 사용 태깅으로 변경해서 작성
     # service.beta.kubernetes.io/aws-load-balancer-type: "nlb"  # 실제로는 이 키가 인식됨
    #service.beta.kubernetes.io/aws-load-balancer-scheme: "internet-facing"
    #service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    #service.beta.kubernetes.io/aws-load-balancer-name: "petclinic-nlb"

  # 기본 어드민 비밀번호(원하면 Secret로 관리)
  adminPassword: "admin"

  # Prometheus + Loki 데이터소스 (UID 고정)
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          uid: PROM
          type: prometheus
          access: proxy
          url: http://kps-kube-prometheus-stack-prometheus.monitoring.svc:9090
          isDefault: true        # ✅ 유일한 default
          jsonData:
            httpMethod: POST
            timeInterval: 15s

        - name: Loki
          uid: LOKI
          type: loki
          access: proxy
          url: http://loki-gateway.monitoring.svc.cluster.local
          isDefault: false
      
  sidecar:
    datasources: # 데이터소스는 상단에 지정해서 들고오기 때문에 false 
      enabled: false
    dashboards:
      enabled: true

  # Correlations 프로비저닝 파일을 마운트할 자리
  extraConfigmapMounts:
    - name: grafana-correlations
      mountPath: /etc/grafana/provisioning/correlations
      configMap: grafana-correlations
      readOnly: true

